<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<!-- <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> -->



<script>
	MathJax = {
		chtml: {
            scale: 0.8
        }
	};
</script>
	<script id="MathJax-script" async
	  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
	</script>

<!-- Import the 3d component -->
<script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>


<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	.line {
		margin:5px 300;
		height:1px;
		background:
			repeating-linear-gradient(to right,rgb(219, 202, 202) 0,rgb(219, 202, 202) 5px,transparent 5px,transparent 7px)
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	code {
  width: 900px;
  font-family: 'Source Code Pro', monospace;
  color: #000000;
  background-color: rgb(232, 231, 231);
  display: block;
}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
	* {
  box-sizing: border-box;
}

.column {
  float: left;
  width: 50.00%;
  padding: 5px;
}

/* Clearfix (clear floats) */
.row::after {
  content: "";
  clear: both;
  display: table;
}

</style>

<html>
<head>
	<title>DDNeRF: Depth Distribution Neural Radiance fields</title>
	<meta property="og:image" content="Path to my teaser.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="DDNeRF: Depth Distribution Neural Radiance fields" />
	<meta property="og:description" content="some description" />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<br>
	<center>
		<span style="font-size:36px">DDNeRF: Depth Distribution Neural Radiance fields</span>
		<table align=center width=600px>
			<table align=center width=600px>
				<tr>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://github.com/dadonda89">David Dadon</a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://www.ohadf.com/">Ohad Fried</a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://faculty.runi.ac.il/toky/">Yacov Hel-Or</a></span>
						</center>
					</td>
				</tr>
			</table>
			<span style="font-size:22px">Department of Computer Science, Reichman University, Israel</span>
			<br>
			<br>
		</table>
	</center>

	<center>
		<video width="640" height="300" controls>
					<source src="./resources/video2.ogv" type="video/ogg"/>
		</video>
		<br>		<br>



		<table align=center width=850px>
			<tr>
				<td align=center width=220px>
					<center>
						<span style="font-size:24px"><a href='https://arxiv.org/abs/2203.16626'>Paper [WACV 2023]</a></span>
					</center>
				</td>
				<td align=center width=150px>
					<center>
						<span style="font-size:24px"><a href='https://github.com/dadonda89/DDNeRF'>Code</a></span><br>
					</center>
				</td>

			</tr>
		</table>

		<br>

	</center>

	<hr>

	<table align=center width=850px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				The field of implicit neural representation has made significant progress.
				Models such as neural radiance fields (NeRF), which uses relatively small
				neural networks, can represent high-quality scenes and achieve state-of-the-art results for novel view
				synthesis. Training these types of networks, however, is still computationally  expensive and the model
				struggles with real life 360<span>&#176;</span> scenes. In this work, we propose the <b> depth distribution
				neural radiance field (DDNeRF) </b>, a new method that significantly increases sampling efficiency along
				rays during training, while achieving superior results for a given sampling budget. DDNeRF achieves
				this performance by learning a more accurate representation of the density distribution along rays.
				More specifically, the proposed framework trains a coarse model to predict the internal distribution
				of the transparency of an input volume along each ray. This estimated distribution then guides the
				sampling procedure of the fine model. Our method allows using fewer samples during training while
				achieving better output quality with the same computational resources.
			</td>
		</tr>
	</table>
	<br>

	<hr>
	<center><h1>Method</h1></center>
	<center><h3>Algorithm Overview</h3></center>
	<table align=center width=150px>

	<tr>
		<td width=320px>
			<center>
				<img class="round" style="width:800px" src="./resources/our_method.png"/>
			</center>
		</td>
	</tr>
	</table>
	<br>
	<br>
	<div style="width:1200px; padding-left: 150px; padding-right: 170px; line-height: 1.px">
		<b>DDNeRF full pipeline:</b> (1) Draw a cone in space and split it into relatively uniform intervals along the depth axis.
		(2) Pass these intervals through an IPE and then through the coarse network to get predictions.
		(3) Render the coarse RGB image. (4) Approximate the density distribution with respect to the coarse samples
		(blue dots) and their Gaussian parameters; then sample the fine samples (purple dots). (5) Pass these samples
		through an IPE and thereafter through the fine network to get predictions. (6) Render the final RGB image and
		depth map.
	</div>
	<br>
	<div class="line"></div>
	<br>
	<br>
	<center><h3>Distribution estimation</h3></center>
	<tr>
		<td width=480px>
			<center>
				<img class="round" style="width:800px" src="./resources/truncation_mixture.png"/>
			</center>
		</td>
	</tr>
	<div style="width:1200px; padding-left: 150px; padding-right: 170px; line-height: 1.px">

		(a) PDF truncation process. The blue and orange curves are the PDF before and after
		truncation; gray marks the region outside the section boundaries. (b) Several
		adjacent truncated PDF distributions. Each orange truncated Gaussian is assigned to an interval;
		The vertical dashed lines are the interval bounds and the horizontal lines are interval weights.
		(c) We combine all distributions into one final distribution.
	</div>

	<center><h3>Training process</h3></center>
	<tr>
		<td width=320px>
			<center>
				<img class="round" style="width:800px" src="./resources/training_process.png"/>
			</center>
		</td>
	</tr>
	<div style="width:1200px; padding-left: 150px; padding-right: 170px; line-height: 1.px">
		Training with <b>eight intervals</b>, Mip-NeRF is
		presented in the first row, DDNeRF in the second row.
	</div>

	<hr>
	<br>
	<table align=center width=900px>
			<!-- <tr> -->
			<center><h1>Results</h1></center>

			<center><h3>Synthetic scenes:</h3></center>
		<div style="width:1200px; padding-left: 150px; padding-right: 170px; line-height: 1.px">
		The first row in each scene was generated by DDNeRF and the second row by Mip-NeRF.
							<br>
							<br>
	</div>

		<table align=center width=800px>
				<tr>
					<td align=center width=100px>
						<center>
							<span style="font-size:20px">4 Samples</a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:20px">8 Samples</a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:20px">16 Samples</a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:20px">32 Samples</a></span>
						</center>
					</td>
				</tr>
			</table>

			<center>
				<img class="round" style="width:800px" src="./resources/synthetic1.png"/>
				<br>
				<img class="round" style="width:800px" src="./resources/synthetic2.png"/>
			</center>

			<center><h3>Forward facing scenes:</h3></center>

		<div style="width:1200px; padding-left: 150px; padding-right: 170px; line-height: 1.px">
		The first row in each scene was generated by DDNeRF and the second row by Mip-NeRF.
							<br>
				<br>

	</div>

		<table align=center width=800px>
				<tr>
					<td align=center width=100px>
						<center>
							<span style="font-size:20px">8 Samples</a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:20px">16 Samples</a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:20px">32 Samples</a></span>
						</center>
					</td>
				</tr>
			</table>

			<center>
				<img class="round" style="width:800px" src="./resources/ff1.png"/>
				<br>
				<img class="round" style="width:800px" src="./resources/ff2.png"/>
			</center>

		<center><h3>360<span>&#176;</span> scenes:</h3></center>

			<center>
				<img class="round" style="width:800px" src="./resources/beta.png"/>
			</center>

			<br>


			<center><h3>360<span>&#176;</span> unbounded scenes:</h3></center>

		<table align=center width=800px>
				<tr>
					<td align=center width=100px>
						<center>
							<span style="font-size:20px">DDNeRF++</a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:20px">NeRF++</a></span>
						</center>
					</td>
				</tr>
			</table>

			<center>
				<img class="round" style="width:800px" src="./resources/ub.png"/>
			</center>

			<br>
		
			
<!--			<center><h3>3D Reconstruction</h3></center>-->
<!--			<center>-->
<!--			<div class="row">-->
<!--					<div class="column"> -->
<!--					<model-viewer alt="GT Rose" camera-controls camera-orbit="0deg 90deg 1m"-->
<!--					style="width: 50%; height: 50%; top: 0px;  position: left; background-color: rgb(255, 255, 255);"-->
<!--					src="rose_mesh_gt.glb" ar ar-modes="webxr scene-viewer quick-look" -->
<!--					seamless-poster shadow-intensity="1" camera-controls enable-pan>-->
<!--					</model-viewer>	-->
<!--					</div>			-->
<!--					-->
<!--					<div class="column">-->
<!--					<model-viewer alt="recovered Rose" camera-controls camera-orbit="0deg 90deg 1m"-->
<!--					style="width: 50%; height: 50%; top: 0px;  position: right; background-color: rgb(255, 255, 255);"-->
<!--					src="rose_mesh.glb" ar ar-modes="webxr scene-viewer quick-look" -->
<!--					seamless-poster shadow-intensity="1" camera-controls enable-pan>-->
<!--					</model-viewer>		-->
<!--					</div>		-->
<!--			</div>-->
<!--		</center>-->
<!--		<center>-->
<!--			<div class="row">-->
<!--					<div class="column"> -->
<!--						Ground Truth 3D-->
<!--					</div>			-->
<!--					-->
<!--					<div class="column">-->
<!--						Estimated 3D-->
<!--					</div>		-->
<!--			</div>-->
		</center>
		</tr>
	</table>



	<hr>

	  
	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Citation</h1></center>
					<pre><code>
	@misc{https://doi.org/10.48550/arxiv.2203.16626,
  doi = {10.48550/ARXIV.2203.16626},

  url = {https://arxiv.org/abs/2203.16626},

  author = {Dadon, David and Fried, Ohad and Hel-Or, Yacov},

  keywords = {Computer Vision and Pattern Recognition (cs.CV), Graphics (cs.GR), FOS: Computer and information sciences, FOS: Computer and information sciences},

  title = {DDNeRF: Depth Distribution Neural Radiance Fields},

  publisher = {arXiv},

  year = {2022},

  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}
					</code></pre>
				</left>
			</td>
		</tr>
	</table>

	<hr>
	<br>
	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					This work was supported by the Israeli Ministry of Science and Technology under The National Foundation for Applied Science (MIA), 
					and by the Israel Science Foundation (grant No. 1574/21).
				</left>
			</td>
		</tr>
	</table>

<br>
<br><br><br>
<p style="text-align:center;font-size:16px;">
    Webpage template from <a href="http://richzhang.github.io/colorization/"> here</a>.
</p>
</body>
</html>

